{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/xc68z2ls0d5gs2zbxxn7vn680000gn/T/ipykernel_23319/3874061143.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Combinar variables\n",
    "def combinar_variables(df):\n",
    "    df['VehicleType'] = df['VehicleType'].fillna('NaN')\n",
    "    df['TransportVehicleType'] = df['VehicleType']\n",
    "    df.loc[df['TransportVehicleType'] == 'NaN', 'TransportVehicleType'] = df['Transport']\n",
    "    df = df.drop(columns=['VehicleType', 'Transport'])\n",
    "    return df\n",
    "\n",
    "# 2. Estandarización de variables numéricas\n",
    "def estandarizar_numericas(df):\n",
    "    numericas = ['GroceryBill', 'DriveDistance', 'WasteBagCount', 'TVPCHours',\n",
    "       'ClothesNew', 'InternetHours']\n",
    "    \n",
    "    datos_stn = pd.DataFrame(\n",
    "        StandardScaler().fit_transform(df[numericas]),  # Datos estandarizados\n",
    "                                    columns=['{}_z'.format(variable) for variable in numericas],  # Nombres de columnas estandarizadas\n",
    "                                    index=df[numericas].index  # Índices (etiquetas de filas) del DataFrame\n",
    "    )\n",
    "\n",
    "    datos_sin_numericas = df.drop(columns=numericas)\n",
    "    df = pd.concat([datos_sin_numericas, datos_stn], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 3. Crear columnas para posibles combinaciones de respuestas\n",
    "def crear_columnas_recycling_cooking(df):\n",
    "    # Define desired categories\n",
    "    desired_recycling_categories = [\"Plastic\", \"Metal\", \"Paper\",\"Glass\"]\n",
    "    desired_cooking_categories = [\"Airfryer\",\"Microwave\", \"Oven\", \"Grill\", \"Stove\"]\n",
    "\n",
    "    # Create columns for desired recycling categories\n",
    "    for item in desired_recycling_categories:\n",
    "        df[f\"Recycling{item}\"] = [1 if item in x else 0 for x in df['Recycling']]\n",
    "\n",
    "    # Create columns for desired cooking categories\n",
    "    for item in desired_cooking_categories:\n",
    "        df[f\"CookingWith{item}\"] = [1 if item in x else 0 for x in df['Cooking_With']]\n",
    "\n",
    "    df = df.drop(columns=['Recycling', 'Cooking_With'])\n",
    "    return df\n",
    "\n",
    "# 4. Codificar variables independientes con una sola respuesta\n",
    "def codificar_variables(df):\n",
    "    encoders = {\n",
    "        \"BodyType\": OrdinalEncoder(categories=[['underweight', 'normal', 'overweight', 'obese']]),\n",
    "        \"Sex\": LabelBinarizer(),\n",
    "        \"ShowerFreq\": OrdinalEncoder(categories=[['less frequently', 'more frequently', 'daily', 'twice a day']]),\n",
    "        \"EnergyHeat\": OneHotEncoder(categories=[['electricity', 'natural gas', 'coal', 'wood']], sparse_output=False),\n",
    "        \"TransportVehicleType\": OneHotEncoder(categories=[['walk/bicycle', 'public','electric', 'hybrid', 'lpg' ,'petrol','diesel']], sparse_output=False),\n",
    "        \"SocialActivity\": OrdinalEncoder(categories=[['never', 'sometimes', 'often']]),\n",
    "        \"AirTravelFreq\": OrdinalEncoder(categories=[['never', 'rarely', 'frequently', 'very frequently']]),\n",
    "        \"WasteBagSize\": OrdinalEncoder(categories=[['small', 'medium', 'large', 'extra large']]),\n",
    "        \"EnergyEfficiency\": OrdinalEncoder(categories=[['No','Sometimes','Yes']]),\n",
    "        \"Diet\": OneHotEncoder(categories=[['pescatarian', 'vegetarian', 'omnivore', 'vegan']], sparse_output=False)\n",
    "    }\n",
    "    # Transform the dataset columns\n",
    "    for column, encoder in encoders.items():\n",
    "        if column == 'EnergyHeat' or column == 'TransportVehicleType' or column == 'Diet':\n",
    "            encoded_data = encoder.fit_transform(df[column].array.reshape(-1, 1))\n",
    "            encoded_columns = encoder.get_feature_names_out([column])\n",
    "\n",
    "            onehot_df = pd.DataFrame(encoded_data, \n",
    "                                    index = df.index,\n",
    "                                    columns=encoded_columns)\n",
    "            onehot_df = onehot_df.astype(int)\n",
    "            df = df.join(onehot_df)\n",
    "            df = df.drop(columns=[column])\n",
    "\n",
    "        else:\n",
    "            df[column] = encoder.fit_transform(df[column].array.reshape(-1, 1))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Crear el pipeline con cada paso de transformación\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('combine', FunctionTransformer(combinar_variables)),\n",
    "    ('scale', FunctionTransformer(estandarizar_numericas)),\n",
    "    ('recycling_cooking', FunctionTransformer(crear_columnas_recycling_cooking)),\n",
    "    ('encode', FunctionTransformer(codificar_variables)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el pipeline\n",
    "with open('pipeline.pkl', 'wb') as f:\n",
    "    dill.dump(pipeline, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
